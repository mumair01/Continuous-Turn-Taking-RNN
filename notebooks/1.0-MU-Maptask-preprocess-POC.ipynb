{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Proof of concept notebook for obtaining and preprocessing MapTask data from \n",
    "my MapTask pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download libraries for environment. \n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "# Env. vars to check if the notebook is running on colab, kaggle etc. \n",
    "IS_COLAB = \"google.colab\" in sys.modules \n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules \n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Install the packages \n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "    %pip install -q -U datasets\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "    # Mount the drive \n",
    "    from google.colab import drive \n",
    "    drive.mount(\"/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import glob \n",
    "import shutil \n",
    "import torch \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --  Set environment global vars. \n",
    "\n",
    "# Shared env. vars. \n",
    "GLOBAL_SEED = 42 \n",
    "IS_CUDA_ENV = torch.cuda.is_available()\n",
    "GLOBAL_DEVICE = torch.device('cuda') if IS_CUDA_ENV else torch.device('cpu')\n",
    "SET_SEED = True # If true, sets the global seeds for this notebook. \n",
    "\n",
    "if IS_LOCAL:\n",
    "    SMALL_DATASET = True if not IS_CUDA_ENV else False # Use a small dataset if no cuda env. \n",
    "    SMALL_DATASET_SIZE = 3 \n",
    "\n",
    "if IS_COLAB:\n",
    "    SMALL_DATASET = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring env. \n",
    "if SET_SEED:\n",
    "    # to make this notebook's output stable across runs\n",
    "    np.random.seed(GLOBAL_SEED) \n",
    "    torch.manual_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Paths\n",
    "NOTEBOOK_NAME = \"1.0-MU-Maptask-preprocess-POC\"\n",
    "PROJECT_ROOT_DIR = \"/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous\" \n",
    "# --- Input data dirs. \n",
    "DATASET_NAME = \"1.0-MU-Maptask-preprocess-POC\"\n",
    "DATASET_TYPE = \"csv\"\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"processed\", DATASET_NAME)\n",
    "RAW_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"raw\", \"maptask\")\n",
    "\n",
    "# --- Result dirs. \n",
    "# NOTE: The model dir will have to change depending on where the models are stored. \n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT_DIR,\"reports\",NOTEBOOK_NAME)\n",
    "\n",
    "os.makedirs(REPORTS_DIR,exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_DIR,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPTASK_DIR = os.path.join(RAW_DATA_DIR,\"maptaskv2-1\")\n",
    "GEMAPS_DIR = os.path.join(RAW_DATA_DIR,\"audio_features/egemaps_v02_50ms\")\n",
    "\n",
    "# Paths within the maptask corpus \n",
    "STEREO_AUDIO_PATH = os.path.join(MAPTASK_DIR,\"Data/signals/dialogues\")\n",
    "MONO_AUDIO_PATH = os.path.join(MAPTASK_DIR,\"Data/signals/mono_signals\")\n",
    "# NOTE: The timed units are also used for Voice Activity annotations. \n",
    "TIMED_UNIT_PATHS = os.path.join(MAPTASK_DIR,\"Data/timed-units\") \n",
    "POS_PATH = os.path.join(MAPTASK_DIR,\"Data/pos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapTask Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANT_LABELS_MAPTASK = [\"f\",\"g\"] # NOTE: f = follower ; g = giver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maptask_participant(csv_path):\n",
    "    filename, ext = os.path.splitext(os.path.basename(csv_path))\n",
    "    filename_split = filename.split(\".\")\n",
    "    participant = filename_split[1]\n",
    "    return participant\n",
    "\n",
    "def get_maptask_dialogue(csv_path):\n",
    "    filename, ext = os.path.splitext(os.path.basename(csv_path))\n",
    "    filename_split = filename.split(\".\")\n",
    "    dialogue = filename_split[0]\n",
    "    return dialogue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_path,dialogue_name, participant,ext):\n",
    "    \"\"\"\n",
    "    Assumption is that the basename . is the dialogue name. \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    data_paths = [p for p in os.listdir(dir_path)]\n",
    "    data_paths = [os.path.join(dir_path,p) for p in data_paths if os.path.splitext(p)[1][1:] == ext]\n",
    "    for path in data_paths:\n",
    "       if get_maptask_dialogue(path) == dialogue_name and \\\n",
    "                get_maptask_participant(path) == participant:\n",
    "            results.append(path)\n",
    "    return results \n",
    "\n",
    "def get_mono_audio(dialogue_name, participant):\n",
    "    return read_data(MONO_AUDIO_PATH,dialogue_name, participant,\"wav\")[0]\n",
    "\n",
    "def get_stereo_audio(dialogue_name):\n",
    "    return read_data(STEREO_AUDIO_PATH,dialogue_name,\"mix\",\"wav\")[0]\n",
    "\n",
    "def get_timed_unit(dialogue_name, participant):\n",
    "    return read_data(TIMED_UNIT_PATHS,dialogue_name, participant,\"xml\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q1ec1', 'q1ec1', 'q1ec2']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the name of all of the dialogues \n",
    "DIALOGUE_NAMES = sorted([ get_maptask_dialogue(p) for p in glob.glob(\"{}/*.xml\".format(TIMED_UNIT_PATHS))])\n",
    "if SMALL_DATASET:\n",
    "    DIALOGUE_NAMES_SPLIT = DIALOGUE_NAMES[:SMALL_DATASET_SIZE]\n",
    "else:\n",
    "    DIALOGUE_NAMES_SPLIT = DIALOGUE_NAMES\n",
    "DIALOGUE_NAMES_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/raw/maptask/maptaskv2-1/Data/timed-units/q1ec1.f.timed-units.xml'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_timed_unit(DIALOGUE_NAMES_SPLIT[0],\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/raw/maptask/maptaskv2-1/Data/signals/mono_signals/q1ec1.f.wav'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mono_audio(DIALOGUE_NAMES_SPLIT[0],\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/raw/maptask/maptaskv2-1/Data/signals/dialogues/q1ec1.mix.wav'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stereo_audio(DIALOGUE_NAMES_SPLIT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/raw/maptask/audio_features/egemaps_v02_50ms/q1ec1.f.eGeMAPSv02.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data(GEMAPS_DIR,DIALOGUE_NAMES_SPLIT[0], \"f\",\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Skantze 2017 - GEeMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in this section is to extract all the features that are required for the original LSTM model. \n",
    "\n",
    "These features include:\n",
    "1. Voice Activity --> From dataset annotations \n",
    "2. Pitch --> From opensmile\n",
    "3. Spectral Stability --> Not sure \n",
    "4. Parts of Speech --> Annotations supplied with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_STEP_MS = 50 # In the original paper, features were extracted every 50 ms. \n",
    "FRAME_SIZE_MS = 50 # In the original paper, each frame was 50 ms long.\n",
    "\n",
    "GEMAPS_CSV_DELIMITER = \";\"\n",
    "\n",
    "# NOTE: These categories are defined in the original paper. \n",
    "# NOTE: There are other features extracted by OpenSmile but they were not defined \n",
    "# in the original paper - and are not used here - but these might be useful later. \n",
    "# Ex. Mfccs. \n",
    "# The names have been adapted for use with the results produced by opensmile. \n",
    "\n",
    "\n",
    "GEMAPS_FREQUENCY_FEATURES = [\n",
    "    'F0semitoneFrom27.5Hz_sma3nz', # Pitch: logarithmic F0 on a semitone frequency scale, starting at 27.5 Hz (semitone 0)\n",
    "    \"jitterLocal_sma3nz\", # Jitter, deviations in individual consecutive F0 period lengths.\n",
    "     # Formant 1, 2, and 3 frequency, centre frequency of first, second, and third formant\n",
    "    \"F1frequency_sma3nz\",\n",
    "    \"F2frequency_sma3nz\", \n",
    "    \"F3frequency_sma3nz\", \n",
    "    \"F1bandwidth_sma3nz\"\n",
    "] \n",
    "    \n",
    "GEMAPS_ENERGY_FEATURES = [\n",
    "    \"shimmerLocaldB_sma3nz\", # Shimmer, difference of the peak amplitudes of consecutive F0 periods.\n",
    "    \"Loudness_sma3\", # Loudness, estimate of perceived signal intensity from an auditory spectrum.\n",
    "    \"HNRdBACF_sma3nz\" # Harmonics-to-Noise Ratio (HNR), relation of energy in harmonic components to energy in noiselike components.\n",
    "]\n",
    "\n",
    "GEMAPS_SPECTRAL_FEATURES = [\n",
    "    \"alphaRatio_sma3\", #  Alpha Ratio, ratio of the summed energy from 50–1000 Hz and 1–5 kHz\n",
    "    \"hammarbergIndex_sma3\",  # Hammarberg Index, ratio of the strongest energy peak in the 0–2 kHz region to the strongest peak in the 2–5 kHz region\n",
    "    # Spectral Slope 0–500 Hz and 500–1500 Hz, linear regression slope of the logarithmic power spectrum within the two given bands\n",
    "    \"slope0-500_sma3\", \n",
    "    \"slope500-1500_sma3\", \n",
    "    # Formant 1, 2, and 3 relative energy, as well as the ratio of the energy of the spectral harmonic\n",
    "    # peak at the first, second, third formant’s centre frequency to the energy of the spectral peak at F0.\n",
    "    \"F1amplitudeLogRelF0_sma3nz\", \n",
    "    \"F2amplitudeLogRelF0_sma3nz\", \n",
    "    \"F3amplitudeLogRelF0_sma3nz\", \n",
    "    \"logRelF0-H1-H2_sma3nz\", # Harmonic difference H1–H2, ratio of energy of the first F0 harmonic (H1) to the energy of the second F0 harmonic (H2)\n",
    "    \"logRelF0-H1-A3_sma3nz\" # Harmonic difference H1–A3, ratio of energy of the first F0 harmonic (H1) to the energy of the highest harmonic in the third formant range (A3).\n",
    "]\n",
    "\n",
    "# These are all the GeMAPS features we are interested in. \n",
    "RELEVANT_GEMAP_FEATURES = GEMAPS_FREQUENCY_FEATURES + GEMAPS_ENERGY_FEATURES + \\\n",
    "    GEMAPS_SPECTRAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for reading GeMaps since the delimiter may be either , or ; \n",
    "# TODO: For some reason q1ec1 is using , as delimiter instead of ; \n",
    "def read_gemaps_as_df(path):\n",
    "    for delimiter in (\",\",\";\"):\n",
    "        try:\n",
    "            gemaps_df = pd.read_csv(path,delimiter=delimiter,index_col=False)\n",
    "            x = gemaps_df[\"frameTime\"]\n",
    "            return gemaps_df\n",
    "        except:\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def verify_correct_gemaps(gemaps_dir, dialogue_name, participant,result_dir):\n",
    "    \"\"\"\n",
    "    Verify that the gemaps data does not have any duplicated frame times and \n",
    "    that there are no null values. \n",
    "    \"\"\"\n",
    "    gemaps_paths = read_data(gemaps_dir,dialogue_name, participant,\"csv\")\n",
    "    for path in gemaps_paths:\n",
    "        filename = os.path.splitext(os.path.basename(path))[0]\n",
    "        gemaps_df = read_gemaps_as_df(path)\n",
    "        # NOTE: This is required because opensmile is producing some duplicated frameTimes. \n",
    "        gemaps_df.drop_duplicates(subset=['frameTime'], inplace=True)\n",
    "        # Drop the 'name' column \n",
    "        gemaps_df.drop(columns=['name'],inplace=True)\n",
    "        # Check that the frameTime steps are as expected \n",
    "        for i in range(len(gemaps_df['frameTime']) -1):\n",
    "            difference = np.abs(gemaps_df['frameTime'].iloc[i+1] - gemaps_df['frameTime'].iloc[i])\n",
    "            assert (FRAME_STEP_MS/1000 - 1e-3) < difference < (FRAME_STEP_MS/1000 + 1e-3) \n",
    "        # Ensure that none of the values is null. \n",
    "        assert not gemaps_df.isnull().values.any()\n",
    "        gemaps_df.to_csv(os.path.join(result_dir,\"{}.csv\".format(filename)), sep=GEMAPS_CSV_DELIMITER)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTED_GEMAPS_DIR = os.path.join(PROCESSED_DATA_DIR,\"corrected_gemaps_50ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isdir(CORRECTED_GEMAPS_DIR):\n",
    "    shutil.rmtree(CORRECTED_GEMAPS_DIR)\n",
    "os.makedirs(CORRECTED_GEMAPS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_correct_gemaps(GEMAPS_DIR,DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[0],CORRECTED_GEMAPS_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dialogue_name in DIALOGUE_NAMES_SPLIT:\n",
    "    for participant in PARTICIPANT_LABELS_MAPTASK:\n",
    "        verify_correct_gemaps(GEMAPS_DIR, dialogue_name, participant,CORRECTED_GEMAPS_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voice Activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum utterance duration for it to be considered voice activity. \n",
    "MINIMUM_VA_CLASSIFICATION_TIME_MS = 25 \n",
    "VOICE_ACTIVITY_LABEL = 1 # This means that voice activity was detected. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: This voice activity is for 50ms intervals. \n",
    "def get_voice_activity_annotations(dialogue_name, participant):\n",
    "    timed_unit_path = get_timed_unit(dialogue_name,participant)\n",
    "    # Read the xml file \n",
    "    tree = xml.etree.ElementTree.parse(timed_unit_path).getroot()\n",
    "    # Extracting the audio end time from te timed units file. \n",
    "    audio_end_time_ms = float(list(tree.iter())[-1].get('end')) *1000\n",
    "    tu_tags = tree.findall('tu')\n",
    "    # Getting all the times in which there are voice activity annotations in the corpus. \n",
    "    va_times = []\n",
    "    for tu_tag in tu_tags:\n",
    "        start_time_s = float(tu_tag.get('start'))\n",
    "        end_time_s = float(tu_tag.get('end'))\n",
    "        if end_time_s - start_time_s >= MINIMUM_VA_CLASSIFICATION_TIME_MS/1000:\n",
    "            va_times.append((start_time_s,end_time_s))\n",
    "    # Get the frame times based on the final times unit time. \n",
    "    # NOTE: This is being generated based on the step size for now. \n",
    "    frame_times_s = np.arange(0,audio_end_time_ms,FRAME_STEP_MS) / 1000\n",
    "    # Array to store voice  activity - initially all zeros means no voice activity. \n",
    "    voice_activity = np.zeros((frame_times_s.shape[0]))\n",
    "    # For each activity detected, get the start and end index of the nearest frame being \n",
    "    # considered from the input audio. \n",
    "    for start_time_s, end_time_s in va_times:\n",
    "        # Obtaining index relative to the frameTimes being considered for \n",
    "        # which there is voice activity. \n",
    "        start_idx = np.abs(frame_times_s-start_time_s).argmin()\n",
    "        end_idx = np.abs(frame_times_s-end_time_s).argmin()\n",
    "        voice_activity[start_idx:end_idx+1] = VOICE_ACTIVITY_LABEL\n",
    "    # Ensure that there are no nan values introduced in the data. \n",
    "    assert not np.isnan(voice_activity).any() and not np.isnan(frame_times_s).any()\n",
    "    return pd.DataFrame({\n",
    "        \"frameTime\" : frame_times_s,\n",
    "        \"voiceActivity\" :  voice_activity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting VA annotations \n",
    "voice_activity = get_voice_activity_annotations(\n",
    "    DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 4939), (2, 365))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.where(voice_activity == 0)).shape, np.array(np.where(voice_activity == VOICE_ACTIVITY_LABEL)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.390159951407167"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: Percentage of frames with voice activity \n",
    "(np.array(np.where(voice_activity == VOICE_ACTIVITY_LABEL)).shape[1] / \\\n",
    "np.array(np.where(voice_activity == 0)).shape[1]) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_activity_save_dir = os.path.join(PROCESSED_DATA_DIR,\"voice_activity_poc\")\n",
    "os.makedirs(voice_activity_save_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the voice activity for both f and g participants. \n",
    "\n",
    "voice_activity_f_df = get_voice_activity_annotations(\n",
    "    DIALOGUE_NAMES_SPLIT[0],\"f\")\n",
    "voice_activity_g_df = get_voice_activity_annotations(\n",
    "    DIALOGUE_NAMES_SPLIT[0],\"g\")\n",
    "voice_activity_f_df.to_csv(\"{}/{}.f.voice_activity.csv\".format(voice_activity_save_dir,DIALOGUE_NAMES_SPLIT[0]))\n",
    "voice_activity_g_df.to_csv(\"{}/{}.g.voice_activity.csv\".format(voice_activity_save_dir,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PITCH_FEATURE_LABELS = \"F0semitoneFrom27.5Hz_sma3nz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the frameTimes \n",
    "# NOTE: Not sure why the original code is doing this. \n",
    "gemaps_path = read_data(CORRECTED_GEMAPS_DIR,DIALOGUE_NAMES_SPLIT[0], \"g\",\"csv\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the amount by which the opensmile features are shifted back\n",
    "# NOTE: This is because we are using a 50ms timestep and the extracted features \n",
    "# are also on a 50 ms timescale. \n",
    "\n",
    "# Read the gemaps feature file. \n",
    "gemaps_df = pd.read_csv(gemaps_path,delimiter=GEMAPS_CSV_DELIMITER,index_col=0)\n",
    "# Extract the relevant raw gemap features into a separate file. \n",
    "relevant_gemaps_df = gemaps_df[RELEVANT_GEMAP_FEATURES]\n",
    "# Obtain the z normalized values for each column individually. \n",
    "z_normalized_feat_df = relevant_gemaps_df.apply(\n",
    "    lambda col: preprocessing.scale(col),axis=1,result_type='broadcast')\n",
    "# Make sure there are no nan values introduced \n",
    "assert not relevant_gemaps_df.isnull().values.any()\n",
    "assert not z_normalized_feat_df.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5301, 26), (5301, 18), (5301, 18))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemaps_df.shape, relevant_gemaps_df.shape, z_normalized_feat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original paper uses both the absolute and relevant pitch values and a \n",
    "# binary label indicating whether the frame was voiced. \n",
    "absolute_pitch = relevant_gemaps_df[PITCH_FEATURE_LABELS]\n",
    "z_normalized_pitch = z_normalized_feat_df[PITCH_FEATURE_LABELS]\n",
    "assert len(absolute_pitch) == len(z_normalized_pitch)\n",
    "# Determine whether frame was voiced \n",
    "frame_times_s = gemaps_df[\"frameTime\"] \n",
    "data = {\n",
    "    \"frameTime\" : frame_times_s,\n",
    "    \"{}Absolute\".format(PITCH_FEATURE_LABELS) : absolute_pitch, \n",
    "    \"{}Znormelized\".format(PITCH_FEATURE_LABELS) : z_normalized_pitch, \n",
    "}\n",
    "pitch_df = pd.DataFrame(data)\n",
    "assert not pitch_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: -- we can merge the VA annotations later / when making the final dataframe. \n",
    "# Merge with VA annotations based on frameTime \n",
    "# NOTE: If we don't merge, then VA annotations df might have extra rows.\n",
    "# pitch_df = pd.merge(pitch_df, voice_activity,on='frameTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_save_dir = os.path.join(PROCESSED_DATA_DIR,\"pitch_poc\")\n",
    "os.makedirs(pitch_save_dir ,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_df.to_csv(\"{}/{}.g.pitch.csv\".format(pitch_save_dir ,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a method for extraction. \n",
    "\n",
    "def extract_pitch(dialogue_name, participant):\n",
    "    # Define the amount by which the opensmile features are shifted back\n",
    "    # NOTE: This is because we are using a 50ms timestep and the extracted features \n",
    "    # are also on a 50 ms timescale. \n",
    "\n",
    "    # Read the gemaps feature file. \n",
    "    gemaps_path = read_data(CORRECTED_GEMAPS_DIR,dialogue_name, participant,\"csv\")[0]\n",
    "    gemaps_df = pd.read_csv(gemaps_path,delimiter=GEMAPS_CSV_DELIMITER,index_col=0)\n",
    "    # Extract the relevant raw gemap features into a separate file. \n",
    "    relevant_gemaps_df = gemaps_df[RELEVANT_GEMAP_FEATURES]\n",
    "    # Obtain the z normalized values for each column individually. \n",
    "    z_normalized_feat_df = relevant_gemaps_df.apply(\n",
    "        lambda col: preprocessing.scale(col),axis=1,result_type='broadcast')\n",
    "    # Make sure there are no nan values introduced \n",
    "    assert not relevant_gemaps_df.isnull().values.any()\n",
    "    assert not z_normalized_feat_df.isnull().values.any()\n",
    "    # The original paper uses both the absolute and relevant pitch values and a \n",
    "    # binary label indicating whether the frame was voiced. \n",
    "    absolute_pitch = relevant_gemaps_df[PITCH_FEATURE_LABELS]\n",
    "    z_normalized_pitch = z_normalized_feat_df[PITCH_FEATURE_LABELS]\n",
    "    assert len(absolute_pitch) == len(z_normalized_pitch)\n",
    "    # Determine whether frame was voiced \n",
    "    frame_times_s = gemaps_df[\"frameTime\"] \n",
    "    data = {\n",
    "        \"frameTime\" : frame_times_s,\n",
    "        \"{}Absolute\".format(PITCH_FEATURE_LABELS) : absolute_pitch, \n",
    "        \"{}Znormalized\".format(PITCH_FEATURE_LABELS) : z_normalized_pitch, \n",
    "    }\n",
    "    pitch_df = pd.DataFrame(data)\n",
    "    assert not pitch_df.isnull().values.any()\n",
    "    return pitch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for both speakers in one file \n",
    "pitch_f_df = extract_pitch(DIALOGUE_NAMES_SPLIT[0], \"f\")\n",
    "pitch_g_df = extract_pitch(DIALOGUE_NAMES_SPLIT[0], \"g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: These files will no longer contain voice activity annotations as these \n",
    "# can be added later. \n",
    "pitch_f_df.to_csv(\"{}/{}.f.pitch.csv\".format(pitch_save_dir ,DIALOGUE_NAMES_SPLIT[0]))\n",
    "pitch_g_df.to_csv(\"{}/{}.g.pitch.csv\".format(pitch_save_dir ,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power / Intensity \n",
    "\n",
    "For now, we consider Loudness from the GeMAPS feature set as a measure of \n",
    "intensity. However, there are other energy related features that may be used \n",
    "later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_save_dir = os.path.join(PROCESSED_DATA_DIR,\"power_poc\")\n",
    "os.makedirs(power_save_dir ,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_FEATURE_LABELS = \"Loudness_sma3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_power(dialogue_name, participant):\n",
    "    # Define the amount by which the opensmile features are shifted back\n",
    "    # NOTE: This is because we are using a 50ms timestep and the extracted features \n",
    "    # are also on a 50 ms timescale. \n",
    "    # Read the gemaps feature file. \n",
    "    gemaps_path = read_data(CORRECTED_GEMAPS_DIR,dialogue_name, participant,\"csv\")[0]\n",
    "    gemaps_df = pd.read_csv(gemaps_path,delimiter=GEMAPS_CSV_DELIMITER,index_col=0)\n",
    "    # Extract the relevant raw gemap features into a separate file. \n",
    "    relevant_gemaps_df = gemaps_df[RELEVANT_GEMAP_FEATURES]\n",
    "    # Obtain the z normalized values for each column individually. \n",
    "    z_normalized_feat_df = relevant_gemaps_df.apply(\n",
    "        lambda col: preprocessing.scale(col),axis=1,result_type='broadcast')\n",
    "    # Make sure there are no nan values introduced \n",
    "    assert not relevant_gemaps_df.isnull().values.any()\n",
    "    assert not z_normalized_feat_df.isnull().values.any()\n",
    "    # The original paper uses power / intensity in dB - \n",
    "    # TODO: Check what the units of loudness are in the GeMAPS set. \n",
    "    absolute_power = relevant_gemaps_df[POWER_FEATURE_LABELS]\n",
    "    z_normalized_power = z_normalized_feat_df[POWER_FEATURE_LABELS]\n",
    "    # Determine whether frame was voiced \n",
    "    frame_times_s = gemaps_df[\"frameTime\"] \n",
    "    data = {\n",
    "        \"frameTime\" : frame_times_s,\n",
    "        \"{}_Absolute\".format(POWER_FEATURE_LABELS) :  absolute_power,\n",
    "        \"{}_Znormalized\".format(POWER_FEATURE_LABELS) : z_normalized_power\n",
    "    }\n",
    "    power_df = pd.DataFrame(data)\n",
    "    assert not power_df.isnull().values.any()\n",
    "    return power_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_f_df = extract_power(DIALOGUE_NAMES_SPLIT[0], \"f\")\n",
    "power_g_df = extract_power(DIALOGUE_NAMES_SPLIT[0], \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "power_f_df.to_csv(\"{}/{}.f.power.csv\".format(power_save_dir,DIALOGUE_NAMES_SPLIT[0]))\n",
    "power_g_df.to_csv(\"{}/{}.g.power.csv\".format(power_save_dir,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral stability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_save_dir = os.path.join(PROCESSED_DATA_DIR,\"spectral_poc\")\n",
    "os.makedirs(spectral_save_dir ,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTRAL_FEATURE_LABELS = 'spectralFlux_sma3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_flux(dialogue_name, participant):\n",
    "    # Define the amount by which the opensmile features are shifted back\n",
    "    # NOTE: This is because we are using a 50ms timestep and the extracted features \n",
    "    # are also on a 50 ms timescale. \n",
    "    # Read the gemaps feature file. \n",
    "    gemaps_path = read_data(CORRECTED_GEMAPS_DIR,dialogue_name, participant,\"csv\")[0]\n",
    "    gemaps_df = pd.read_csv(gemaps_path,delimiter=GEMAPS_CSV_DELIMITER)\n",
    "    # Extract the relevant raw gemap features into a separate file. \n",
    "    spectral_flux_df = gemaps_df[SPECTRAL_FEATURE_LABELS]\n",
    "    # Obtain the z normalized values for each column individually. \n",
    "    z_normalized_spectral_flux = preprocessing.scale(spectral_flux_df)\n",
    "    # Make sure there are no nan values introduced \n",
    "    assert not spectral_flux_df.isnull().values.any()\n",
    "    assert not  np.isnan(z_normalized_spectral_flux).any()\n",
    "    # Determine whether frame was voiced \n",
    "    frame_times_s = gemaps_df[\"frameTime\"] \n",
    "    data = {\n",
    "        \"frameTime\" : frame_times_s,\n",
    "        \"{}_Znormalized\".format(SPECTRAL_FEATURE_LABELS) : z_normalized_spectral_flux\n",
    "    }\n",
    "    result_df = pd.DataFrame(data)\n",
    "    assert not result_df.isnull().values.any()\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_flux_f_df = extract_spectral_flux(DIALOGUE_NAMES_SPLIT[0], \"f\")\n",
    "spectral_flux_g_df = extract_spectral_flux(DIALOGUE_NAMES_SPLIT[0], \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "spectral_flux_f_df .to_csv(\"{}/{}.f.spectral_flux.csv\".format(spectral_save_dir,DIALOGUE_NAMES_SPLIT[0]))\n",
    "spectral_flux_g_df .to_csv(\"{}/{}.g.spectral_flux.csv\".format(spectral_save_dir,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of Speech Annotations\n",
    "\n",
    "These are directly obtained from the annotations received with the MapTask corpus. \n",
    "\n",
    "In the original paper, there are 59 different POS tags, and all the tags are \n",
    "represented as a one hot feature vector. Additionally, to simulate the delay \n",
    "in extracting POS tags, the feature vector was set to 0 by default but the \n",
    "corresponding feature vector was set to 1 (since it is a one-hot encoded vector)\n",
    "a 100ms after the word had ended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_DELAY_TIME_MS = 100 # Assume that each POS calculation is delayed by 100ms. \n",
    "\n",
    "\n",
    "# Create a vocabulary from all the POS annotation tags\n",
    "# Documentation to the MapTask POS tags:  https://groups.inf.ed.ac.uk/maptask/interface/expl.html\n",
    "POS_TAGS = [\n",
    "    \"vb\", \n",
    "    \"vbd\", \n",
    "    \"vbg\",\n",
    "    \"vbn\", \n",
    "    \"vbz\",\n",
    "    \"nn\",\n",
    "    \"nns\",\n",
    "    \"np\",\n",
    "    \"jj\",\n",
    "    \"jjr\",\n",
    "    \"jjt\",\n",
    "    \"ql\",\n",
    "    \"qldt\",\n",
    "    \"qlp\",\n",
    "    \"rb\",\n",
    "    \"rbr\",\n",
    "    \"wql\",\n",
    "    \"wrb\",\n",
    "    \"not\",\n",
    "    \"to\",\n",
    "    \"be\",\n",
    "    \"bem\",\n",
    "    \"ber\",\n",
    "    \"bez\",\n",
    "    \"do\",\n",
    "    \"doz\",\n",
    "    \"hv\",\n",
    "    \"hvz\",\n",
    "    \"md\",\n",
    "    \"dpr\",\n",
    "    \"at\",\n",
    "    \"dt\",\n",
    "    \"ppg\",\n",
    "    \"wdt\",\n",
    "    \"ap\",\n",
    "    \"cd\",\n",
    "    \"od\",\n",
    "    \"gen\",\n",
    "    \"ex\",\n",
    "    \"pd\",\n",
    "    \"wps\",\n",
    "    \"wpo\",\n",
    "    \"pps\",\n",
    "    \"ppss\",\n",
    "    \"ppo\",\n",
    "    \"ppl\",\n",
    "    \"ppg2\\\"\",\n",
    "    \"pr\",\n",
    "    \"pn\",\n",
    "    \"in\",\n",
    "    \"rp\",\n",
    "    \"cc\",\n",
    "    \"cs\",\n",
    "    \"aff\",\n",
    "    \"fp\",\n",
    "    \"noi\",\n",
    "    \"pau\",\n",
    "    \"frag\",\n",
    "    \"sent\"\n",
    "]\n",
    "len(POS_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_save_dir = os.path.join(PROCESSED_DATA_DIR,\"pos_poc\")\n",
    "os.makedirs(pos_save_dir ,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to read the timed-unit file for the corresponding start and end times \n",
    "# for the tags since we need to assign it\n",
    "timed_unit_path = read_data(\n",
    "    TIMED_UNIT_PATHS,DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[1],\"xml\")[0]\n",
    "tree_timed_unit = xml.etree.ElementTree.parse(timed_unit_path).getroot()\n",
    "timed_unit_tags = list(tree_timed_unit.iter())\n",
    "tu_tags = tree_timed_unit.findall(\"tu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the appropriate pos file\n",
    "pos_path = read_data(\n",
    "    POS_PATH,DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[1],\"xml\")[0]\n",
    "tree_pos = xml.etree.ElementTree.parse(pos_path).getroot()\n",
    "# The pos is the tag attribute in all the tw tags. \n",
    "tw_tags = tree_pos.findall(\"tw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting all the times in which there are voice activity annotations in the corpus. \n",
    "va_times = []\n",
    "for tu_tag in tu_tags:\n",
    "    start_time_s = float(tu_tag.get('start'))\n",
    "    end_time_s = float(tu_tag.get('end'))\n",
    "    if end_time_s - start_time_s >= MINIMUM_VA_CLASSIFICATION_TIME_MS/1000:\n",
    "        va_times.append((start_time_s,end_time_s))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 5.0000e-02, 1.0000e-01, ..., 2.6495e+02, 2.6500e+02,\n",
       "       2.6505e+02])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the audio end time from te timed units file. \n",
    "audio_end_time_ms = float(list(tree_timed_unit.iter())[-1].get('end')) *1000\n",
    "# Get the frame times based on the final times unit time. \n",
    "# NOTE: This is being generated based on the step size for now. \n",
    "frame_times_s = np.arange(0,audio_end_time_ms,FRAME_STEP_MS) / 1000\n",
    "# Ensure that there are no null values here. \n",
    "assert not np.isnan(frame_times_s).any()\n",
    "frame_times_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5302"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to have a POS annotation per frame - not simply per detected word time. \n",
    "pos_annotations = [0] * frame_times_s.shape[0] \n",
    "len(pos_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the end time of the word and the corresponding POS tag. \n",
    "word_annotations = []\n",
    "for tu_tag in tu_tags:\n",
    "    tu_tag_id = tu_tag.get(\"id\")[7:]\n",
    "    end_time_s = float(tu_tag.get('end'))\n",
    "    for tw_tag in tw_tags:\n",
    "        # NOTE: Not sure if this is the correct way to extract the corresponding \n",
    "        # timed-unit id. \n",
    "        href = list(tw_tag.iter())[1].get(\"href\")\n",
    "        href_filename, href_ids = href.split(\"#\")\n",
    "        # Look at the appropriate file tags based on the filename. \n",
    "        href_ids = href_ids.split(\"..\")\n",
    "        for href_id in href_ids:\n",
    "            href_id = href_id[href_id.find(\"(\")+8:href_id.rfind(\")\")]\n",
    "            if href_id == tu_tag_id:\n",
    "                word_annotations.append((end_time_s,tw_tag.get(\"tag\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_to_idx = {}\n",
    "idx_to_pos_tag = {}\n",
    "# NOTE: Indices start from 1 here because 0 already represents unknown categories. \n",
    "for i,tag in enumerate(POS_TAGS):\n",
    "    pos_tags_to_idx[tag] = i +1\n",
    "    idx_to_pos_tag[i+1] = tag \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all the collected word end times and POS tags, we need to introduce \n",
    "# a delay and add the POS annotation to the delayed frame. \n",
    "pos_annotations = np.zeros((frame_times_s.shape[0]))\n",
    "for end_time_s, pos_tag in word_annotations:\n",
    "    frame_idx = np.abs(frame_times_s-(end_time_s +POS_DELAY_TIME_MS/1000)).argmin()\n",
    "    pos_annotations[frame_idx] = pos_tags_to_idx[pos_tag] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        52, 53, 54, 55, 56, 57, 58, 59])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This encoder will ignore any unknown tags by replacing them with all zeros. \n",
    "onehot_encoder = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")\n",
    "onehot_encoder.fit(np.asarray(list(pos_tags_to_idx.values())).reshape(-1,1))\n",
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder.categories_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5302, 59)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: The POS annotation file may have data for more time frames than the \n",
    "# audio features extracted from opensmile. Therefore, when merging later, \n",
    "# we should always merge the audio features first. \n",
    "encoded_pos = onehot_encoder.transform(pos_annotations.reshape(-1,1))\n",
    "encoded_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vb</th>\n",
       "      <th>vbd</th>\n",
       "      <th>vbg</th>\n",
       "      <th>vbn</th>\n",
       "      <th>vbz</th>\n",
       "      <th>nn</th>\n",
       "      <th>nns</th>\n",
       "      <th>np</th>\n",
       "      <th>jj</th>\n",
       "      <th>jjr</th>\n",
       "      <th>...</th>\n",
       "      <th>in</th>\n",
       "      <th>rp</th>\n",
       "      <th>cc</th>\n",
       "      <th>cs</th>\n",
       "      <th>aff</th>\n",
       "      <th>fp</th>\n",
       "      <th>noi</th>\n",
       "      <th>pau</th>\n",
       "      <th>frag</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5302 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vb  vbd  vbg  vbn  vbz   nn  nns   np   jj  jjr  ...   in   rp   cc  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5297  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5298  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5299  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5300  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5301  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       cs  aff   fp  noi  pau  frag  sent  \n",
       "0     0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "...   ...  ...  ...  ...  ...   ...   ...  \n",
       "5297  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5298  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5299  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5300  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5301  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5302 rows x 59 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the extracted features and saving. \n",
    "pos_annotations_df = pd.DataFrame(encoded_pos,columns=POS_TAGS)\n",
    "pos_annotations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinging the above individual cells to create a single method to extract POS \n",
    "# features \n",
    "\n",
    "def extract_pos_annotations_with_delay(dialogue_name, participant):\n",
    "    # Need to read the timed-unit file for the corresponding start and end times \n",
    "    # for the tags since we need to assign it\n",
    "    timed_unit_path = read_data(\n",
    "        TIMED_UNIT_PATHS,dialogue_name,participant,\"xml\")[0]\n",
    "    tree_timed_unit = xml.etree.ElementTree.parse(timed_unit_path).getroot()\n",
    "    tu_tags = tree_timed_unit.findall(\"tu\")\n",
    "    # Read the appropriate pos file\n",
    "    pos_path = read_data(POS_PATH,dialogue_name,participant,\"xml\")[0]\n",
    "    tree_pos = xml.etree.ElementTree.parse(pos_path).getroot()\n",
    "    # The pos is the tag attribute in all the tw tags. \n",
    "    tw_tags = tree_pos.findall(\"tw\")\n",
    "    # Getting all the times in which there are voice activity annotations in the corpus. \n",
    "    va_times = []\n",
    "    for tu_tag in tu_tags:\n",
    "        start_time_s = float(tu_tag.get('start'))\n",
    "        end_time_s = float(tu_tag.get('end'))\n",
    "        if end_time_s - start_time_s >= MINIMUM_VA_CLASSIFICATION_TIME_MS/1000:\n",
    "            va_times.append((start_time_s,end_time_s))\n",
    "    # Extracting the audio end time from the timed units file. \n",
    "    audio_end_time_ms = float(list(tree_timed_unit.iter())[-1].get('end')) *1000\n",
    "    # Get the frame times based on the final times unit time. \n",
    "    # NOTE: This is being generated based on the step size for now. \n",
    "    frame_times_s = np.arange(0,audio_end_time_ms,FRAME_STEP_MS) / 1000\n",
    "    # Collecting the end time of the word and the corresponding POS tag. \n",
    "    word_annotations = []\n",
    "    for tu_tag in tu_tags:\n",
    "        tu_tag_id = tu_tag.get(\"id\")[7:]\n",
    "        end_time_s = float(tu_tag.get('end'))\n",
    "        for tw_tag in tw_tags:\n",
    "            # NOTE: Not sure if this is the correct way to extract the corresponding \n",
    "            # timed-unit id. \n",
    "            href = list(tw_tag.iter())[1].get(\"href\")\n",
    "            href_filename, href_ids = href.split(\"#\")\n",
    "            # Look at the appropriate file tags based on the filename. \n",
    "            href_ids = href_ids.split(\"..\")\n",
    "            for href_id in href_ids:\n",
    "                href_id = href_id[href_id.find(\"(\")+8:href_id.rfind(\")\")]\n",
    "                if href_id == tu_tag_id:\n",
    "                    if tw_tag.get(\"tag\") in POS_TAGS:\n",
    "                        word_annotations.append((end_time_s,tw_tag.get(\"tag\")))\n",
    "    # For all the collected word end times and POS tags, we need to introduce \n",
    "    # a delay and add the POS annotation to the delayed frame. \n",
    "    pos_annotations = np.zeros((frame_times_s.shape[0]))\n",
    "    for end_time_s, pos_tag in word_annotations:\n",
    "        frame_idx = np.abs(frame_times_s-(end_time_s +POS_DELAY_TIME_MS/1000)).argmin()\n",
    "        # Convert to integer based on the vocabulary dictionary. \n",
    "        pos_annotations[frame_idx] = pos_tags_to_idx[pos_tag] \n",
    "    # The pos annotations should not have any nan values \n",
    "    assert not np.isnan(pos_annotations).any()\n",
    "    # This encoder will ignore any unknown tags by replacing them with all zeros. \n",
    "    onehot_encoder = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")\n",
    "    onehot_encoder.fit(np.asarray(list(pos_tags_to_idx.values())).reshape(-1,1))\n",
    "    encoded_pos = onehot_encoder.transform(pos_annotations.reshape(-1,1))\n",
    "    pos_annotations_df = pd.DataFrame(encoded_pos,columns=POS_TAGS)\n",
    "    # Add frametimes to the df \n",
    "    pos_annotations_df.insert(0,\"frameTime\",frame_times_s)\n",
    "    # Remove any duplicated frameTimes \n",
    "    pos_annotations_df.drop_duplicates(subset=['frameTime'], inplace=True)\n",
    "    assert not pos_annotations_df.isnull().values.any()\n",
    "    return pos_annotations_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_annotations_f_df = extract_pos_annotations_with_delay(\n",
    "    DIALOGUE_NAMES_SPLIT[0], \"f\")\n",
    "pos_annotations_g_df = extract_pos_annotations_with_delay(\n",
    "    DIALOGUE_NAMES_SPLIT[0], \"g\")\n",
    "pos_annotations_f_df.to_csv(\"{}/{}.f.pos_onehot.csv\".format(pos_save_dir,DIALOGUE_NAMES_SPLIT[0]))\n",
    "pos_annotations_g_df.to_csv(\"{}/{}.g.pos_onehot.csv\".format(pos_save_dir,DIALOGUE_NAMES_SPLIT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_save_dir = os.path.join(PROCESSED_DATA_DIR,\"pipeline_poc\")\n",
    "os.makedirs(pipeline_save_dir ,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Can be made more efficient by putting each extraction into its own thread.\n",
    "def extract_skantze_2017_features(dialogue_name, participant, output_dir,feature_set):\n",
    "    # Get the VA annotations from maptask. \n",
    "    voice_activity_df = get_voice_activity_annotations(\n",
    "        dialogue_name, participant)\n",
    "\n",
    "    # Get pitch, power, and flux from the opensmile audio features \n",
    "    pitch_df = extract_pitch(dialogue_name, participant)\n",
    "    power_df = extract_power(dialogue_name, participant)\n",
    "    spectral_flux_df = extract_spectral_flux(dialogue_name, participant)\n",
    "\n",
    "    if feature_set == \"prosody\":\n",
    "        # Does not include pos features\n",
    "        result_df = reduce(lambda x,y: pd.merge(\n",
    "        x,y, on='frameTime', how='inner'),\n",
    "        [voice_activity_df,pitch_df,power_df,spectral_flux_df])\n",
    "    # POS annotations only extracted for the full dataset. \n",
    "    elif feature_set ==\"full\":\n",
    "        pos_df = extract_pos_annotations_with_delay(dialogue_name, participant)\n",
    "        result_df = reduce(lambda x,y: pd.merge(\n",
    "            x,y, on='frameTime', how='inner'),\n",
    "            [voice_activity_df,pitch_df,power_df,spectral_flux_df,pos_df])\n",
    "    else:\n",
    "        raise Exception(\"Feature set not supported\")\n",
    "        \n",
    "    result_df.to_csv(\"{}/{}.{}.skantze_2017_features.{}.csv\".format(\n",
    "        output_dir,dialogue_name,participant,feature_set))\n",
    "    # Make sure there are no nan values \n",
    "    assert not result_df.isnull().values.any()\n",
    "    return result_df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frameTime</th>\n",
       "      <th>voiceActivity</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nzAbsolute</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nzZnormalized</th>\n",
       "      <th>Loudness_sma3_Absolute</th>\n",
       "      <th>Loudness_sma3_Znormalized</th>\n",
       "      <th>spectralFlux_sma3_Znormalized</th>\n",
       "      <th>vb</th>\n",
       "      <th>vbd</th>\n",
       "      <th>vbg</th>\n",
       "      <th>...</th>\n",
       "      <th>in</th>\n",
       "      <th>rp</th>\n",
       "      <th>cc</th>\n",
       "      <th>cs</th>\n",
       "      <th>aff</th>\n",
       "      <th>fp</th>\n",
       "      <th>noi</th>\n",
       "      <th>pau</th>\n",
       "      <th>frag</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.414430</td>\n",
       "      <td>0.181512</td>\n",
       "      <td>-0.414211</td>\n",
       "      <td>-0.355010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.409845</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>-0.409593</td>\n",
       "      <td>-0.201524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.405466</td>\n",
       "      <td>0.172331</td>\n",
       "      <td>-0.405204</td>\n",
       "      <td>-0.103440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.411621</td>\n",
       "      <td>0.144899</td>\n",
       "      <td>-0.411431</td>\n",
       "      <td>-0.164591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416682</td>\n",
       "      <td>0.104665</td>\n",
       "      <td>-0.416558</td>\n",
       "      <td>-0.233114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>264.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.389374</td>\n",
       "      <td>0.339836</td>\n",
       "      <td>-0.388882</td>\n",
       "      <td>4.040398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>264.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.394844</td>\n",
       "      <td>0.270952</td>\n",
       "      <td>-0.394457</td>\n",
       "      <td>3.761027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>264.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.402629</td>\n",
       "      <td>0.507726</td>\n",
       "      <td>-0.401937</td>\n",
       "      <td>2.955869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>264.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.410715</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>-0.410069</td>\n",
       "      <td>3.894783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>265.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413982</td>\n",
       "      <td>0.508740</td>\n",
       "      <td>-0.413355</td>\n",
       "      <td>4.011532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5301 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frameTime  voiceActivity  F0semitoneFrom27.5Hz_sma3nzAbsolute  \\\n",
       "0          0.00            0.0                                  0.0   \n",
       "1          0.05            0.0                                  0.0   \n",
       "2          0.10            0.0                                  0.0   \n",
       "3          0.15            0.0                                  0.0   \n",
       "4          0.20            0.0                                  0.0   \n",
       "...         ...            ...                                  ...   \n",
       "5296     264.80            1.0                                  0.0   \n",
       "5297     264.85            1.0                                  0.0   \n",
       "5298     264.90            1.0                                  0.0   \n",
       "5299     264.95            1.0                                  0.0   \n",
       "5300     265.00            1.0                                  0.0   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nzZnormalized  Loudness_sma3_Absolute  \\\n",
       "0                                  -0.414430                0.181512   \n",
       "1                                  -0.409845                0.186722   \n",
       "2                                  -0.405466                0.172331   \n",
       "3                                  -0.411621                0.144899   \n",
       "4                                  -0.416682                0.104665   \n",
       "...                                      ...                     ...   \n",
       "5296                               -0.389374                0.339836   \n",
       "5297                               -0.394844                0.270952   \n",
       "5298                               -0.402629                0.507726   \n",
       "5299                               -0.410715                0.498677   \n",
       "5300                               -0.413982                0.508740   \n",
       "\n",
       "      Loudness_sma3_Znormalized  spectralFlux_sma3_Znormalized   vb  vbd  vbg  \\\n",
       "0                     -0.414211                      -0.355010  0.0  0.0  0.0   \n",
       "1                     -0.409593                      -0.201524  0.0  0.0  0.0   \n",
       "2                     -0.405204                      -0.103440  0.0  0.0  0.0   \n",
       "3                     -0.411431                      -0.164591  0.0  0.0  0.0   \n",
       "4                     -0.416558                      -0.233114  0.0  0.0  0.0   \n",
       "...                         ...                            ...  ...  ...  ...   \n",
       "5296                  -0.388882                       4.040398  0.0  0.0  0.0   \n",
       "5297                  -0.394457                       3.761027  0.0  0.0  0.0   \n",
       "5298                  -0.401937                       2.955869  0.0  0.0  0.0   \n",
       "5299                  -0.410069                       3.894783  0.0  0.0  0.0   \n",
       "5300                  -0.413355                       4.011532  0.0  0.0  0.0   \n",
       "\n",
       "      ...   in   rp   cc   cs  aff   fp  noi  pau  frag  sent  \n",
       "0     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "1     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "2     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "3     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "4     ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...  \n",
       "5296  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5297  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5298  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5299  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "5300  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5301 rows x 66 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skantze_2017_features(\n",
    "    DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[0],pipeline_save_dir,\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frameTime</th>\n",
       "      <th>voiceActivity</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nzAbsolute</th>\n",
       "      <th>F0semitoneFrom27.5Hz_sma3nzZnormalized</th>\n",
       "      <th>Loudness_sma3_Absolute</th>\n",
       "      <th>Loudness_sma3_Znormalized</th>\n",
       "      <th>spectralFlux_sma3_Znormalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.414430</td>\n",
       "      <td>0.181512</td>\n",
       "      <td>-0.414211</td>\n",
       "      <td>-0.355010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.409845</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>-0.409593</td>\n",
       "      <td>-0.201524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.405466</td>\n",
       "      <td>0.172331</td>\n",
       "      <td>-0.405204</td>\n",
       "      <td>-0.103440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.411621</td>\n",
       "      <td>0.144899</td>\n",
       "      <td>-0.411431</td>\n",
       "      <td>-0.164591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.416682</td>\n",
       "      <td>0.104665</td>\n",
       "      <td>-0.416558</td>\n",
       "      <td>-0.233114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>264.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.389374</td>\n",
       "      <td>0.339836</td>\n",
       "      <td>-0.388882</td>\n",
       "      <td>4.040398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>264.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.394844</td>\n",
       "      <td>0.270952</td>\n",
       "      <td>-0.394457</td>\n",
       "      <td>3.761027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>264.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.402629</td>\n",
       "      <td>0.507726</td>\n",
       "      <td>-0.401937</td>\n",
       "      <td>2.955869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>264.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.410715</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>-0.410069</td>\n",
       "      <td>3.894783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>265.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413982</td>\n",
       "      <td>0.508740</td>\n",
       "      <td>-0.413355</td>\n",
       "      <td>4.011532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5301 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frameTime  voiceActivity  F0semitoneFrom27.5Hz_sma3nzAbsolute  \\\n",
       "0          0.00            0.0                                  0.0   \n",
       "1          0.05            0.0                                  0.0   \n",
       "2          0.10            0.0                                  0.0   \n",
       "3          0.15            0.0                                  0.0   \n",
       "4          0.20            0.0                                  0.0   \n",
       "...         ...            ...                                  ...   \n",
       "5296     264.80            1.0                                  0.0   \n",
       "5297     264.85            1.0                                  0.0   \n",
       "5298     264.90            1.0                                  0.0   \n",
       "5299     264.95            1.0                                  0.0   \n",
       "5300     265.00            1.0                                  0.0   \n",
       "\n",
       "      F0semitoneFrom27.5Hz_sma3nzZnormalized  Loudness_sma3_Absolute  \\\n",
       "0                                  -0.414430                0.181512   \n",
       "1                                  -0.409845                0.186722   \n",
       "2                                  -0.405466                0.172331   \n",
       "3                                  -0.411621                0.144899   \n",
       "4                                  -0.416682                0.104665   \n",
       "...                                      ...                     ...   \n",
       "5296                               -0.389374                0.339836   \n",
       "5297                               -0.394844                0.270952   \n",
       "5298                               -0.402629                0.507726   \n",
       "5299                               -0.410715                0.498677   \n",
       "5300                               -0.413982                0.508740   \n",
       "\n",
       "      Loudness_sma3_Znormalized  spectralFlux_sma3_Znormalized  \n",
       "0                     -0.414211                      -0.355010  \n",
       "1                     -0.409593                      -0.201524  \n",
       "2                     -0.405204                      -0.103440  \n",
       "3                     -0.411431                      -0.164591  \n",
       "4                     -0.416558                      -0.233114  \n",
       "...                         ...                            ...  \n",
       "5296                  -0.388882                       4.040398  \n",
       "5297                  -0.394457                       3.761027  \n",
       "5298                  -0.401937                       2.955869  \n",
       "5299                  -0.410069                       3.894783  \n",
       "5300                  -0.413355                       4.011532  \n",
       "\n",
       "[5301 rows x 7 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skantze_2017_features(\n",
    "    DIALOGUE_NAMES_SPLIT[0],PARTICIPANT_LABELS_MAPTASK[0], pipeline_save_dir,\"prosody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool \n",
    "# Multiprocessing has issues running in jupyter -  using multiprocess instead. \n",
    "import multiprocess as mp\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-threaded function to extract the Skantze features \n",
    "\n",
    "def extract_skantze_2017_features_multithreaded(\n",
    "        dialogue_names_split, output_dir, feature_set=\"full\", num_workers=4):\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(output_dir)\n",
    "    assert os.path.isdir(output_dir)\n",
    "    print(\"Running pipeline for {} dialogues, each for participants {}...\".format(\n",
    "        len(dialogue_names_split),PARTICIPANT_LABELS_MAPTASK))\n",
    "    # Collect all the arguments for the non-multithread method. \n",
    "    collected_args = []\n",
    "    for dialogue_name in dialogue_names_split:\n",
    "        for participant in PARTICIPANT_LABELS_MAPTASK:\n",
    "            collected_args.append(\n",
    "                (dialogue_name,participant, output_dir,feature_set))\n",
    "    print(\"Using {} workers...\".format(num_workers))\n",
    "    with mp.Pool(num_workers) as pool:\n",
    "        results = list(tqdm.tqdm(pool.starmap(\n",
    "            extract_skantze_2017_features, collected_args),\n",
    "            total=len(collected_args),desc=\"Extracting Features\"))\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Elapsed time: {:.3f} seconds\".format(elapsed_time))\n",
    "    print(\"Results saved to {}\".format(output_dir))\n",
    "    print(\"Completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_results_path = os.path.join(PROCESSED_DATA_DIR,\"skantze2017_pipeline\")\n",
    "os.makedirs(pipeline_results_path,exist_ok=True)\n",
    "pipeline_results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline\n",
      "Running pipeline for 3 dialogues, each for participants ['f', 'g']...\n",
      "Using 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 6/6 [00:00<00:00, 15837.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 16.695 seconds\n",
      "Results saved to /Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline\n",
      "Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extract_skantze_2017_features_multithreaded(\n",
    "    DIALOGUE_NAMES_SPLIT,pipeline_results_path ,\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline\n",
      "Running pipeline for 3 dialogues, each for participants ['f', 'g']...\n",
      "Using 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 6/6 [00:00<00:00, 29093.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 14.086 seconds\n",
      "Results saved to /Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline\n",
      "Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_skantze_2017_features_multithreaded(\n",
    "    DIALOGUE_NAMES_SPLIT,pipeline_results_path ,\"prosody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec2.g.skantze_2017_features.full.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec1.f.skantze_2017_features.full.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec2.f.skantze_2017_features.full.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec1.g.skantze_2017_features.full.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec1.f.skantze_2017_features.prosody.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec2.f.skantze_2017_features.prosody.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec1.g.skantze_2017_features.prosody.csv',\n",
       " '/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_pipeline/q1ec2.g.skantze_2017_features.prosody.csv']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the results and make sure there are no nan values \n",
    "extracted_feature_set_paths = glob.glob(\"{}/*.csv\".format(pipeline_results_path))\n",
    "extracted_feature_set_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in extracted_feature_set_paths:\n",
    "    feature_df = pd.read_csv(path,delimiter=\",\")\n",
    "    assert not feature_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_feature_sets/full\n",
      "Running pipeline for 256 dialogues, each for participants ['f', 'g']...\n",
      "Using 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 512/512 [00:00<00:00, 704323.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4405.649 seconds\n",
      "Results saved to /Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_feature_sets/full\n",
      "Completed!\n",
      "/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_feature_sets/prosody\n",
      "Running pipeline for 256 dialogues, each for participants ['f', 'g']...\n",
      "Using 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 512/512 [00:00<00:00, 445906.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1870.222 seconds\n",
      "Results saved to /Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/1.0-MU-Maptask-preprocess-POC/skantze2017_feature_sets/prosody\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This cell extracts all the feature sets for all files - and will take \n",
    "# a while to run. \n",
    "# TODO: Still need to add ability to the pipeline to generate feature sets \n",
    "# with different frame step sizes (This notebook only does for 50ms). \n",
    "# Once that is done, UPDATE scripts to reflect the completed pipeline. \n",
    "\n",
    "for feature_set in (\"full\", \"prosody\"):\n",
    "    # Set up the directories. \n",
    "    output_dir_path = os.path.join(PROCESSED_DATA_DIR, \"skantze2017_feature_sets\",feature_set)\n",
    "    if os.path.isdir(output_dir_path):\n",
    "        shutil.rmtree(output_dir_path)\n",
    "    os.makedirs(output_dir_path)\n",
    "    # First, produce a corrected version of all the dialogues\n",
    "    for dialogue_name in DIALOGUE_NAMES:\n",
    "        for participant in PARTICIPANT_LABELS_MAPTASK:\n",
    "            verify_correct_gemaps(GEMAPS_DIR, dialogue_name, participant,CORRECTED_GEMAPS_DIR) \n",
    "    # Extract the features \n",
    "    extract_skantze_2017_features_multithreaded(\n",
    "        DIALOGUE_NAMES, output_dir_path , feature_set)\n",
    "    # Ensure that all the data is correct \n",
    "    extracted_feature_set_paths = glob.glob(\"{}/*.csv\".format(output_dir_path))\n",
    "    for path in extracted_feature_set_paths:\n",
    "        feature_df = pd.read_csv(path,delimiter=\",\")\n",
    "        assert not feature_df.isnull().values.any()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('trp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2304c455ac551f7a45279e05896e7a6c75d8c847965e97ef85e853390a9b358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
