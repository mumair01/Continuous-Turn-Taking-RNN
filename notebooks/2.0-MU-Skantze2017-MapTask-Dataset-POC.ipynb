{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "The goal in this notebook is to take the specific GeMaps feature csv files required \n",
    "for this project and create a Dataset class for the Skantze2017 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download libraries for environment. \n",
    "\n",
    "import sys \n",
    "import os \n",
    "\n",
    "# Env. vars to check if the notebook is running on colab, kaggle etc. \n",
    "IS_COLAB = \"google.colab\" in sys.modules \n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules \n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Install the packages \n",
    "    %pip install -q -U tensorflow-addons\n",
    "    %pip install -q -U transformers\n",
    "    %pip install -q -U datasets\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "    # Mount the drive \n",
    "    from google.colab import drive \n",
    "    drive.mount(\"/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Tensorflow imports \n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "\n",
    "# Pytorch imports \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Others \n",
    "import glob \n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --  Set environment global vars. \n",
    "\n",
    "# Shared env. vars. \n",
    "GLOBAL_SEED = 42 \n",
    "IS_CUDA_ENV = torch.cuda.is_available()\n",
    "GLOBAL_DEVICE = torch.device('cuda') if IS_CUDA_ENV else torch.device('cpu')\n",
    "SET_SEED = True # If true, sets the global seeds for this notebook. \n",
    "# LIMITED_RESOURCES = not IS_CUDA_ENV\n",
    "LIMITED_RESOURCES = False \n",
    "\n",
    "if LIMITED_RESOURCES:\n",
    "    SMALL_DATASET_SIZE = 10\n",
    "\n",
    "if IS_COLAB:\n",
    "    SMALL_DATASET = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring env. \n",
    "if SET_SEED:\n",
    "    # to make this notebook's output stable across runs\n",
    "    np.random.seed(GLOBAL_SEED) \n",
    "    torch.manual_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Paths\n",
    "NOTEBOOK_NAME = \"2.0-MU-Skantze2017-MapTask-Dataset-POC\"\n",
    "PROJECT_ROOT_DIR = \"/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous\" \n",
    "# --- Input data dirs. \n",
    "DATASET_NAME = \"maptask\" # NOTE: MapTask contains the full and prosody feature sets. \n",
    "DATASET_TYPE = \"csv\"\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"processed\", DATASET_NAME)\n",
    "RAW_DATA_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\", \"raw\", \"maptask\")\n",
    "\n",
    "# --- Result dirs. \n",
    "# NOTE: The model dir will have to change depending on where the models are stored. \n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT_DIR,\"reports\",NOTEBOOK_NAME)\n",
    "SAVE_DATASET_DIR = os.path.join(PROJECT_ROOT_DIR,\"data\",\"processed\",NOTEBOOK_NAME)\n",
    "\n",
    "\n",
    "os.makedirs(REPORTS_DIR,exist_ok=True)\n",
    "os.makedirs(SAVE_DATASET_DIR,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadumair/Documents/Repositories/mumair01-repos/TRP-Modeling/skantze_2017_continuous/data/processed/maptask/full'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to the specific feature sets \n",
    "FULL_PROCESSED_FEATURE_DIR = os.path.join(PROCESSED_DATA_DIR,\"full\")\n",
    "PROSODY_PROCESSED_FEATURE_DIR = os.path.join(PROCESSED_DATA_DIR,\"prosody\")\n",
    "FULL_PROCESSED_FEATURE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPTASK_DIR = os.path.join(RAW_DATA_DIR,\"maptaskv2-1\")\n",
    "# Paths within the maptask corpus \n",
    "STEREO_AUDIO_PATH = os.path.join(MAPTASK_DIR,\"Data/signals/dialogues\")\n",
    "MONO_AUDIO_PATH = os.path.join(MAPTASK_DIR,\"Data/signals/mono_signals\")\n",
    "# NOTE: The timed units are also used for Voice Activity annotations. \n",
    "TIMED_UNIT_PATHS = os.path.join(MAPTASK_DIR,\"Data/timed-units\") \n",
    "POS_PATH = os.path.join(MAPTASK_DIR,\"Data/pos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maptask_participant(csv_path):\n",
    "    filename, ext = os.path.splitext(os.path.basename(csv_path))\n",
    "    filename_split = filename.split(\".\")\n",
    "    participant = filename_split[1]\n",
    "    return participant\n",
    "\n",
    "def get_maptask_dialogue(csv_path):\n",
    "    filename, ext = os.path.splitext(os.path.basename(csv_path))\n",
    "    filename_split = filename.split(\".\")\n",
    "    dialogue = filename_split[0]\n",
    "    return dialogue\n",
    "\n",
    "def read_data(dir_path,dialogue_name, participant,ext):\n",
    "    \"\"\"\n",
    "    Assumption is that the basename . is the dialogue name. \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    data_paths = [p for p in os.listdir(dir_path)]\n",
    "    data_paths = [os.path.join(dir_path,p) for p in data_paths if os.path.splitext(p)[1][1:] == ext]\n",
    "    for path in data_paths:\n",
    "       if get_maptask_dialogue(path) == dialogue_name and \\\n",
    "                get_maptask_participant(path) == participant:\n",
    "            results.append(path)\n",
    "    return results \n",
    "\n",
    "def get_mono_audio(dialogue_name, participant):\n",
    "    return read_data(MONO_AUDIO_PATH,dialogue_name, participant,\"wav\")[0]\n",
    "\n",
    "def get_stereo_audio(dialogue_name):\n",
    "    return read_data(STEREO_AUDIO_PATH,dialogue_name,\"mix\",\"wav\")[0]\n",
    "\n",
    "def get_timed_unit(dialogue_name, participant):\n",
    "    return read_data(TIMED_UNIT_PATHS,dialogue_name, participant,\"xml\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dialogue_features(dialogue_names, features_dir):\n",
    "    \"\"\"\n",
    "    Collect the dialogue f and g feature files.\n",
    "    Assumes that features_dir contains both the f and g feature files. \n",
    "    \"\"\"\n",
    "    collected = {}\n",
    "    for dialogue in dialogue_names:\n",
    "        collected[dialogue] = {\n",
    "            \"f\" : read_data(features_dir,dialogue,\"f\",\"csv\")[0], \n",
    "            \"g\" : read_data(features_dir,dialogue,\"g\",\"csv\")[0]}\n",
    "    return collected \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed data. \n",
    "dataset_csv_paths =  glob.glob(\"{}/*.csv\".format(FULL_PROCESSED_FEATURE_DIR))\n",
    "\n",
    "if LIMITED_RESOURCES:\n",
    "    dataset_csv_paths = dataset_csv_paths[:SMALL_DATASET_SIZE]\n",
    "\n",
    "len(dataset_csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_maptask_participant(dataset_csv_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q3nc7'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_maptask_dialogue(dataset_csv_paths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Voice Activity Labels \n",
    "\n",
    "Here, we want to be able to generate target voice activity labels depending \n",
    "on the length of the prediction window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_STEP_SIZE_MS = 50\n",
    "PREDICTION_SIZE_MS = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_voice_activity_labels(feature_df, N):\n",
    "    # TODO: FIx the delimiter \n",
    "    feature_df = feature_df[[\"frameTime\",\"voiceActivity\"]]\n",
    "    assert not feature_df.isnull().values.any()\n",
    "    frame_times_ms = np.asarray(feature_df[\"frameTime\"])\n",
    "    voice_activity_annotations = np.asarray(feature_df[\"voiceActivity\"])\n",
    "    assert frame_times_ms.shape[0] == voice_activity_annotations.shape[0]\n",
    "    labels = np.zeros((frame_times_ms.shape[0],N)) # target label shape: Num Frames x N\n",
    "    for i in range(len(frame_times_ms)):\n",
    "        # Pad the last labels with 0 if the conversation has ended \n",
    "        if i + N > len(frame_times_ms):\n",
    "            concat = np.concatenate(\n",
    "                [voice_activity_annotations[i:],\n",
    "                 np.zeros(N - (len(frame_times_ms)-i))])\n",
    "            labels[i] = concat\n",
    "        else:\n",
    "            labels[i] = voice_activity_annotations[i:i+N]\n",
    "    labels_df = pd.DataFrame(labels) \n",
    "    labels_df.insert(0,\"frameTime\",frame_times_ms)\n",
    "    assert not labels_df.isnull().values.any()\n",
    "    return labels_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE; Here, 20 means the next 50ms * 20 i.e., the next one second. \n",
    "N = int(PREDICTION_SIZE_MS/FRAME_STEP_SIZE_MS)\n",
    "N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv(dataset_csv_paths[0], delimiter=\",\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frameTime</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8025</th>\n",
       "      <td>401.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>401.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8027</th>\n",
       "      <td>401.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>401.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8029</th>\n",
       "      <td>401.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frameTime    0    1    2    3    4\n",
       "0          0.00  0.0  0.0  0.0  0.0  0.0\n",
       "1          0.05  0.0  0.0  0.0  0.0  0.0\n",
       "2          0.10  0.0  0.0  0.0  0.0  0.0\n",
       "3          0.15  0.0  0.0  0.0  0.0  0.0\n",
       "4          0.20  0.0  0.0  0.0  0.0  0.0\n",
       "...         ...  ...  ...  ...  ...  ...\n",
       "8025     401.25  0.0  1.0  1.0  1.0  1.0\n",
       "8026     401.30  1.0  1.0  1.0  1.0  0.0\n",
       "8027     401.35  1.0  1.0  1.0  0.0  0.0\n",
       "8028     401.40  1.0  1.0  0.0  0.0  0.0\n",
       "8029     401.45  1.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[8030 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "extract_voice_activity_labels(feature_df, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splits \n",
    "\n",
    "We want to split the MapTask files into different files based on the dialogue. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_dialogues(dataset_paths, test_size=0.25, val_size=0.2, \n",
    "        seed=GLOBAL_SEED):\n",
    "    dataset_paths = deepcopy(dataset_paths)\n",
    "    dialogue_names = sorted(list(set([get_maptask_dialogue(p) for p in dataset_paths])))\n",
    "    train_dialogues, test_dialogues = train_test_split(dialogue_names, \n",
    "        test_size=test_size,random_state=seed)\n",
    "    train_dialogues, val_dialogues = train_test_split(train_dialogues, \n",
    "        test_size=val_size,random_state=seed)\n",
    "    return train_dialogues, val_dialogues, test_dialogues \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 20, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dialogues, val_dialogues, test_dialogues = get_train_val_test_dialogues(dataset_csv_paths)\n",
    "len(train_dialogues), len(val_dialogues), len(test_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_paths_map =  collect_dialogue_features(\n",
    "    train_dialogues,FULL_PROCESSED_FEATURE_DIR)\n",
    "len(feature_paths_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapTask Training Dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we develop a dataset that can be used to train the Skantze 2017 model using the MapTask corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(feature_paths_map[train_dialogues[0]][\"g\"],index_col=0,delimiter=\",\")\n",
    "len(df.columns[df.columns != \"frameTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Skantze2017VAPredictionMapTaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Maptask dataset for voice activity annotation sequence prediction.  \n",
    "    NOTE: Needs a large amount of memory to load this. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_paths_map, sequence_length_ms, \n",
    "            prediction_length_ms, target_participant, frame_step_size_ms):\n",
    "        # Vars. \n",
    "        self.feature_paths_map = feature_paths_map \n",
    "        self.sequence_length_ms = sequence_length_ms \n",
    "        self.prediction_length_ms = prediction_length_ms \n",
    "        self.target_participant = target_participant \n",
    "        self.frame_step_size_ms = frame_step_size_ms \n",
    "        # Calculated \n",
    "        self.num_context_frames = int(sequence_length_ms / frame_step_size_ms)\n",
    "        self.num_target_frames = int(prediction_length_ms / frame_step_size_ms)\n",
    "        # Storage \n",
    "        self.xs = [] \n",
    "        self.ys = [] \n",
    "        for dialogue in list(self.feature_paths_map.keys()):\n",
    "            self.__load_data(dialogue)\n",
    "        assert len(self.xs) == len(self.ys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx > self.__len__():\n",
    "            raise Exception \n",
    "        return self.xs[idx], self.ys[idx]\n",
    "\n",
    "    def __load_data(self, dialogue):\n",
    "        s0_feature_df, s1_feature_df = self.__load_dataframes(dialogue)\n",
    "        # Extract the voice activity labels for s0 as the target labels\n",
    "        s0_target_labels_df = extract_voice_activity_labels(\n",
    "            s0_feature_df,self.num_target_frames)\n",
    "        # Make sure none of the dfs have any nan values \n",
    "        assert not s0_feature_df.isnull().values.any() and \\\n",
    "            not s1_feature_df.isnull().values.any() and \\\n",
    "            not s0_target_labels_df.isnull().values.any()\n",
    "        # Trim the dataframes to the same length \n",
    "        min_num_frames = np.min([len(s0_feature_df.index),len(s1_feature_df.index)])\n",
    "        s0_feature_df = s0_feature_df[:min_num_frames]\n",
    "        s1_feature_df = s1_feature_df[:min_num_frames]\n",
    "        s0_target_labels_df = s0_target_labels_df[:min_num_frames]\n",
    "        # Make sure they all have common frametimes\n",
    "        assert s0_feature_df['frameTime'].equals(s1_feature_df['frameTime'])\n",
    "        assert s0_feature_df['frameTime'].equals(s0_target_labels_df['frameTime'])\n",
    "        s0_s1_df = pd.concat([s0_feature_df,s1_feature_df],axis=1)     \n",
    "        assert not s0_s1_df.isnull().values.any()     \n",
    "        # Determine the number of sequences for this dialogue \n",
    "        num_sequences = int(np.floor(len(s0_feature_df.index))/self.num_context_frames)\n",
    "        for i in range(num_sequences):\n",
    "            x = np.asarray(s0_s1_df.loc[:,s0_s1_df.columns != 'frameTime'][i * \\\n",
    "                self.num_context_frames : (i * self.num_context_frames) \\\n",
    "                    + self.num_context_frames])\n",
    "            y = np.asarray(s0_target_labels_df.loc[:,s0_target_labels_df.columns\\\n",
    "                    != 'frameTime'][i * self.num_context_frames : \\\n",
    "                        (i * self.num_context_frames) + self.num_context_frames])[-1,:]\n",
    "            self.xs.append(x)\n",
    "            self.ys.append(y)\n",
    "\n",
    "    def __load_dataframes(self, dialogue):\n",
    "        if self.target_participant == \"f\":\n",
    "            s0_feature_df = pd.read_csv(self.feature_paths_map[dialogue][\"f\"], index_col=0,delimiter=\",\") \n",
    "            s1_feature_df = pd.read_csv(self.feature_paths_map[dialogue][\"g\"],index_col=0,delimiter=\",\")\n",
    "        else:\n",
    "            s0_feature_df = pd.read_csv(self.feature_paths_map[dialogue][\"g\"],index_col=0,delimiter=\",\") \n",
    "            s1_feature_df = pd.read_csv(self.feature_paths_map[dialogue][\"f\"],index_col=0,delimiter=\",\")\n",
    "        return s0_feature_df, s1_feature_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Skantze2017VAPredictionMapTaskDataset(\n",
    "    feature_paths_map=feature_paths_map, \n",
    "    sequence_length_ms=60_000, \n",
    "    prediction_length_ms=3000, \n",
    "    target_participant=\"f\", \n",
    "    frame_step_size_ms=FRAME_STEP_SIZE_MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 130), (60,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))[0].shape,next(iter(dataset))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:Seed worker can be used to ensure reproducibility in DataLoader \n",
    "# across runs. \n",
    "def seed_worker(worker_id):\n",
    "    worker_seed =GLOBAL_SEED\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def generate_dataloader(dataset, batch_size=32, shuffle=True, num_workers=0, \n",
    "        drop_last=True, pin_memory=True):\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle, \n",
    "        num_workers=num_workers, \n",
    "        drop_last=drop_last, # We always want to remove the last incomplete batch. \n",
    "        pin_memory=pin_memory, \n",
    "        worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fc24865dd90>, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataloader for the data \n",
    "dataloader = DataLoader(dataset, batch_size = 32)\n",
    "dataloader, len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to iterate over dataloader: 1.3312 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for x_batch, y_batch in dataloader:\n",
    "    pass \n",
    "print(\"Total time taken to iterate over dataloader: {:.4f} secs\".format(\n",
    "    time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Feature Datasets For Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 20 32\n"
     ]
    }
   ],
   "source": [
    "# Saving a dataloader for the dataset \n",
    "\n",
    "feature_set = \"full\"\n",
    "if feature_set == \"full\":\n",
    "    features_dir = FULL_PROCESSED_FEATURE_DIR\n",
    "else:\n",
    "    features_dir = PROSODY_PROCESSED_FEATURE_DIR\n",
    "\n",
    "save_dir = os.path.join(SAVE_DATASET_DIR,feature_set)\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "dataset_csv_paths =  glob.glob(\"{}/*.csv\".format(features_dir))\n",
    "\n",
    "train_dialogues, val_dialogues, test_dialogues = \\\n",
    "    get_train_val_test_dialogues(dataset_csv_paths)\n",
    "print(len(train_dialogues), len(val_dialogues), len(test_dialogues))\n",
    "\n",
    "datasets = [] \n",
    "for dialogues in (train_dialogues, val_dialogues, test_dialogues):\n",
    "    dataset = Skantze2017VAPredictionMapTaskDataset(\n",
    "        feature_paths_map=collect_dialogue_features(\n",
    "                                dialogues,features_dir), \n",
    "        sequence_length_ms=60_000, \n",
    "        prediction_length_ms=3000, \n",
    "        target_participant=\"f\", \n",
    "        frame_step_size_ms=FRAME_STEP_SIZE_MS)\n",
    "    datasets.append(deepcopy(dataset))\n",
    "\n",
    "for i, (dataset_name, batch_size) in enumerate(zip(('train','val','test'),(32,32,1))):\n",
    "    dataloader = generate_dataloader(datasets[i],batch_size=batch_size)\n",
    "    path = \"{}/{}_dataloader_{}.pt\".format(save_dir, dataset_name, feature_set)\n",
    "    torch.save(dataloader,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7fc0c6c28e50>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fbfecad6ee0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fc2486e0550>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the saved models \n",
    "\n",
    "dataloaders = [] \n",
    "for dataset_name in ('train','val','test'):\n",
    "    path = \"{}/{}_dataloader_{}.pt\".format(save_dir, dataset_name, feature_set)\n",
    "    dataloader = torch.load(path)\n",
    "    dataloaders.append(deepcopy(dataloader))\n",
    "dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('trp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2304c455ac551f7a45279e05896e7a6c75d8c847965e97ef85e853390a9b358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
